<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>Math for Machines</title>
        <link>https://mathformachines.com</link>
        <description><![CDATA[A blog about data science and machine learning, with a lot of math.]]></description>
        <atom:link href="https://mathformachines.com/feeds/geometry.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Tue, 12 Nov 2019 00:00:00 UT</lastBuildDate>
        <item>
    <title>Visualizing Linear Transformations</title>
    <link>https://mathformachines.com/posts/visualizing-linear-transformations/index.html</link>
    <description><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Say <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> are <a href="https://en.wikipedia.org/wiki/Vector_space">vector spaces</a> with scalars in some <a href="https://en.wikipedia.org/wiki/Field_(mathematics)">field</a> <span class="math inline">\(\mathbb{F}\)</span> (the real numbers, maybe). A <strong><a href="https://en.wikipedia.org/wiki/Linear_map">linear map</a></strong> is a function <span class="math inline">\(T : V \rightarrow W \)</span> satisfying two conditions:</p>
<ul>
<li><strong>additivity</strong> <span class="math inline">\(T(x + y) = T x + T y\)</span> for all <span class="math inline">\(x, y \in V\)</span></li>
<li><strong>homogeneity</strong> <span class="math inline">\(T(c x) = c (T x)\)</span> for all <span class="math inline">\(c \in \mathbb{F} \)</span> and all <span class="math inline">\(x \in V\)</span></li>
</ul>
<p>

<p>Defining a linear map this way just ensures that anything that acts like a vector in <span class="math inline">\(V\)</span> also acts like a vector in <span class="math inline">\(W\)</span> after you map it over. It means that the map preserves all the structure of a vector space after it’s applied.</p>
<p>It’s a simple definition – which is good – but doesn’t speak much to the imagination. Since linear algebra is possibly the <a href="https://math.stackexchange.com/questions/256682/why-study-linear-algebra">most useful</a> and <a href="https://math.stackexchange.com/questions/256682/why-study-linear-algebra">most ubiquitous</a> of all the branches of mathematics, we’d like to have some intuition about what linear maps are so we have some idea of what we’re doing <a href="https://en.wikipedia.org/wiki/Linear_regression">when</a> <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">we</a> <a href="https://en.wikipedia.org/wiki/Backpropagation">use</a> <a href="https://en.wikipedia.org/wiki/Mapreduce">it</a>. Though not all vectors live there, the <a href="https://en.wikipedia.org/wiki/Euclidean_space">Euclidean plane</a> <span class="math inline">\(\mathbb{R}^2\)</span> is certainly the easiest to visualize, and the way we <a href="https://en.wikipedia.org/wiki/Euclidean_distance">measure distance</a> there is very similar to the way we <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">measure error</a> in statistics, so we can feel that our intuitions will carry over.</p>
<p>It turns out that all linear maps in <span class="math inline">\(\mathbb{R}^2\)</span> can be factored into just a few primitive geometric operations: <a href="https://en.wikipedia.org/wiki/Scaling_(geometry)">scaling</a>, <a href="https://en.wikipedia.org/wiki/Rotation_(mathematics)">rotation</a>, and <a href="https://en.wikipedia.org/wiki/Reflection_(mathematics)">reflection</a>. This isn’t the only way to factor these maps, but I think it’s the easiest to understand. (We could get by <a href="https://en.wikipedia.org/wiki/Cartan%E2%80%93Dieudonn%C3%A9_theorem">without rotations</a>, in fact.)</p>
<figure>
<img src="/images/primitives.png" title="primitives" alt="The unit circle, rotated, reflected, and scaled." /><figcaption>The unit circle, rotated, reflected, and scaled.</figcaption>
</figure>
<h1 id="three-primitive-transformations">Three Primitive Transformations</h1>
<h2 id="scaling">Scaling</h2>
<p>A (non-uniform) <strong>scaling transformation</strong> <span class="math inline">\(D\)</span> in <span class="math inline">\(\mathbb{R}^2\)</span> is given by a <a href="https://en.wikipedia.org/wiki/Diagonal_matrix">diagonal matrix</a>:</p>
<p><span class="math display">\[Scl(d1, d2) = \begin{bmatrix}
d_1 &amp; 0   \\
0   &amp; d_2 \\
\end{bmatrix}\]</span></p>
<p>where <span class="math inline">\(d_1\)</span> and <span class="math inline">\(d_2\)</span> are non-negative. The transformation has the effect of stretching or shrinking a vector along each coordinate axis, and, so long as <span class="math inline">\(d_1\)</span> and <span class="math inline">\(d_2\)</span> are positive, it will also preserve the <a href="https://en.wikipedia.org/wiki/Orientation_(vector_space)">orientation</a> of vectors after mapping because in this case <span class="math inline">\(\det(D) = d_1 d_2 &gt; 0\)</span>.</p>
<p>For instance, here is the effect on a vector of this matrix: <span class="math display">\[D = \begin{bmatrix}
0.75 &amp; 0 \\
0    &amp; 1.25 \\
\end{bmatrix}\]</span></p>
<figure>
<img src="/images/vector-scaled.png" title="vector-scaled" alt="A vector, scaled." width="400" /><figcaption>A vector, scaled.</figcaption>
</figure>
<p>It will shrink a vector by a factor of 0.75 along the x-axis and stretch a vector by a factor of 1.25 along the y-axis.</p>
<p>If we think about all the vectors of length 1 as being the points of the <a href="https://en.wikipedia.org/wiki/Unit_circle">unit circle</a>, then we can get an idea of how the transformation will affect any vector. We can see a scaling as a continous transformation beginning at the <a href="https://en.wikipedia.org/wiki/Identity_matrix">identity matrix</a>.</p>
<video autoplay loop mutued playsinline controls>
  <source src="../../images/scaling.webm" type="video/webm">
  <source src="../../images/scaling.mp4" type="video/mp4">
  <source src="../../images/scaling.ogg" type="video/ogg">
</video>

<p>If one of the diagonal entries is 0, then it will collapse the circle on the other axis.</p>
<p><span class="math display">\[D = \begin{bmatrix}
0 &amp; 0 \\
0 &amp; 1.25 \\
\end{bmatrix}\]</span></p>
<p>This is an example of a <a href="https://en.wikipedia.org/wiki/Rank_(linear_algebra)">rank-deficient</a> matrix. It maps every vector onto the y-axis, and so its image has a dimension less than the dimension of the full space.</p>
<video autoplay loop mutued playsinline controls>
  <source src="../../images/collapsed.webm" type="video/webm">
  <source src="../../images/collapsed.mp4" type="video/mp4">
  <source src="../../images/collapsed.ogg" type="video/ogg">
</video>

<h2 id="rotation">Rotation</h2>
<p>A <strong>rotation transformation</strong> <span class="math inline">\(Ref\)</span> is given by a matrix: <span class="math display">\[Ref(\theta) = \begin{bmatrix}
\cos(\theta) &amp; -\sin(\theta) \\
\sin(\theta) &amp; \cos(\theta) \\
\end{bmatrix}\]</span></p>
<p>This transformation will have the effect of rotating a vector counter-clockwise by an angle <span class="math inline">\(\theta\)</span>, when <span class="math inline">\(\theta\)</span> is positive, and clockwise by <span class="math inline">\(\theta\)</span> when <span class="math inline">\(\theta\)</span> is negative.</p>
<figure>
<img src="/images/vector-rotated.png" title="vector-rotated" alt="A vector, rotated by 3\pi/4" width="400" /><figcaption>A vector, rotated by <span class="math inline">\(3\pi/4\)</span></figcaption>
</figure>
<p>And the unit circle gets mapped onto itself.</p>
<video autoplay loop mutued playsinline controls>
  <source src="../../images/rotation.webm" type="video/webm">
  <source src="../../images/rotation.mp4" type="video/mp4">
  <source src="../../images/rotation.ogg" type="video/ogg">
</video>

<p>It shouldn’t be too hard to convince ourselves that the matrix we’ve written down is the one we want. Take some unit vector and write its coordinates like <span class="math inline">\((\cos\gamma, \sin\gamma)\)</span>. Multiply it by <span class="math inline">\(Ref(\theta)\)</span> to get <span class="math inline">\((\cos\gamma \cos\theta - \sin\gamma \sin\theta, \cos\gamma \sin\theta + \sin\gamma \cos\theta)\)</span>. But by a <a href="https://en.wikipedia.org/wiki/List_of_trigonometric_identities#Angle_sum_and_difference_identities">trigonometric identity</a>, this is exactly the vector <span class="math inline">\((\cos(\gamma + \theta), \sin(\gamma + \theta))\)</span>, which is our vector rotated by <span class="math inline">\(\theta\)</span>.</p>
<p>A rotation should preserve not only orientations, but also distances. Now, recall that the determinant for a <span class="math inline">\(2\times 2\)</span> matrix <span class="math inline">\(\begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}\)</span> is <span class="math inline">\(a d - b c\)</span>. So a rotation matrix will have determinant <span class="math inline">\(\cos^2(\theta) + \sin^2(\theta)\)</span>, which, by the <a href="https://en.wikipedia.org/wiki/Pythagorean_trigonometric_identity">Pythagorean identity</a>, is equal to 1. This, together with the fact that its columns are <a href="https://en.wikipedia.org/wiki/Orthonormality">orthonormal</a> means that it does preserve both. It is a kind of <a href="https://en.wikipedia.org/wiki/Orthogonal_matrix">orthogonal matrix</a>, which is a kind of <a href="https://en.wikipedia.org/wiki/Isometry">isometry</a>.</p>
<h2 id="reflection">Reflection</h2>
<p>A <strong>reflection</strong> in <span class="math inline">\(\mathbb{R}^2\)</span> can be described with matricies like: <span class="math display">\[Ref(\theta) = \begin{bmatrix}
\cos(2\theta) &amp; \sin(2\theta) \\
\sin(2\theta) &amp; -\cos(2\theta) \\
\end{bmatrix}\]</span> where the reflection is through a line crossing the origin and forming an angle <span class="math inline">\(\theta\)</span> with the x-axis.</p>
<figure>
<img src="/images/vector-reflected.png" title="vector-reflected" alt="A vector, reflected over a line at angle \pi/4." width="400" /><figcaption>A vector, reflected over a line at angle <span class="math inline">\(\pi/4\)</span>.</figcaption>
</figure>
<p>And the unit circle gets mapped onto itself.</p>
<video autoplay loop mutued playsinline controls>
  <source src="../../images/reflection.webm" type="video/webm">
  <source src="../../images/reflection.mp4" type="video/mp4">
  <source src="../../images/reflection.ogg" type="video/ogg">
</video>

<p>Note that the determinant of this matrix is -1, which means that it <em>reverses</em> orientation. But its columns are still orthonormal, and so it too is an isometry.</p>
<h1 id="decomposing-matricies-into-primitives">Decomposing Matricies into Primitives</h1>
<p>The <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">singular value decomposition</a> (SVD) will factor any matrix <span class="math inline">\(A\)</span> having like this:</p>
<p><span class="math display">\[ A = U \Sigma V^* \]</span></p>
<p>We are working with real matricies, so <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> will both be orthogonal matrices. This means each of these will be either a reflection or a rotation, depending on the pattern of signs in its entries. The matrix <span class="math inline">\(\Sigma\)</span> is a diagonal matrix with non-negative entries, which means that it is a scaling transform. (The <span class="math inline">\(*\)</span> on the <span class="math inline">\(V\)</span> is the <a href="https://en.wikipedia.org/wiki/Conjugate_transpose">conjugate-transpose</a> operator, which just means ordinary <a href="https://en.wikipedia.org/wiki/Transpose">transpose</a> when <span class="math inline">\(V\)</span> doesn’t contain any imaginary entries. So, for us, <span class="math inline">\(V^* = V^\top\)</span>.) Now with the SVD we can rewrite any linear transformation as:</p>
<ol>
<li><span class="math inline">\(V^*\)</span>: Rotate/Reflect</li>
<li><span class="math inline">\(\Sigma\)</span>: Scale</li>
<li><span class="math inline">\(U\)</span>: Rotate/Reflect</li>
</ol>
<h2 id="example">Example</h2>
<p><span class="math display">\[\begin{bmatrix}
0.5 &amp; 1.5 \\
1.5 &amp; 0.5
\end{bmatrix} \approx \begin{bmatrix}
-0.707 &amp; -0.707 \\
-0.707 &amp; 0.707
\end{bmatrix} \begin{bmatrix}
2.0 &amp; 0.0 \\
0.0 &amp; 1.0
\end{bmatrix} \begin{bmatrix}
-0.707 &amp; -0.707 \\
0.707 &amp; -0.707
\end{bmatrix} \]</span></p>
<p>This turns out to be:</p>
<ol>
<li><span class="math inline">\(V^*\)</span>: Rotate clockwise by <span class="math inline">\(\theta = \frac{3 \pi}{4}\)</span>.</li>
<li><span class="math inline">\(\Sigma\)</span>: Scale x-coordinate by <span class="math inline">\(d_1 = 2\)</span> and y-coordinate by <span class="math inline">\(d_2 = 1\)</span>.</li>
<li><span class="math inline">\(U\)</span>: Reflect over the line with angle <span class="math inline">\(-\frac{3\pi}{8}\)</span>.</li>
</ol>
<video autoplay loop mutued playsinline controls>
  <source src="../../images/rot-scale-ref.webm" type="video/webm">
  <source src="../../images/rot-scale-ref.mp4" type="video/mp4">
  <source src="../../images/rot-scale-ref.ogg" type="video/ogg">
</video>

<h2 id="example-1">Example</h2>
<p>And here is a <a href="https://en.wikipedia.org/wiki/Shear_mapping">shear transform</a>, represented as: rotation, scale, rotation.</p>
<span class="math display">\[\begin{bmatrix}
1.0 &amp; 1.0 \\
0.0 &amp; 1.0
\end{bmatrix} \approx \begin{bmatrix}
0.85 &amp; -0.53 \\
0.53 &amp; 0.85
\end{bmatrix} \begin{bmatrix}
1.62 &amp; 0.0 \\
0.0 &amp; 0.62
\end{bmatrix} \begin{bmatrix}
0.53 &amp; 0.85 \\
-0.85 &amp; 0.53
\end{bmatrix}
\]</span>
<video autoplay loop mutued playsinline controls>
  <source src="../../images/shear.webm" type="video/webm">
  <source src="../../images/shear.mp4" type="video/mp4">
  <source src="../../images/shear.ogg" type="video/ogg">
</video>
]]></description>
    <pubDate>Tue, 12 Nov 2019 00:00:00 UT</pubDate>
    <guid>https://mathformachines.com/posts/visualizing-linear-transformations/index.html</guid>
    <dc:creator>Ryan Holbrook</dc:creator>
</item>

    </channel>
</rss>
