
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Visualizing What Convnets Learn</title>
    <link href="https://fonts.googleapis.com/css?family=Merriweather:400&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro&display=swap" rel="stylesheet"> 
    <link href="https://unpkg.com/primer/build/build.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/style.css" />
      <!-- Syntax highlighting -->
  <link rel="stylesheet" href="../../css/github.css" />
  <script src="../../scripts/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  </head>
  <body class="bg-gray-dark">
    <div class="container-xxxl h-100 my-3">
      <div class="box-shadow-large bg-gray">

        <header id="header" class="bg-white">

  <div class="p-4" style="text-align: center">

    <a class="title" href="../../">
      Math for Machines
    </a>

  </div>
  
  <nav class="UnderlineNav UnderlineNav--left px-2 border-top">
    <div class="UnderlineNav-body">
      <a class="UnderlineNav-item" href="../../about/">
        <span style="font-size:1.25em;font-weight:bold">About</span>
      </a>
      <a class="UnderlineNav-item" href="../../courses/">
        <span style="font-size:1.25em;font-weight:bold">Kaggle Courses</span>
      </a>
      <a class="UnderlineNav-item" href="../../competitions/">
        <span style="font-size:1.25em;font-weight:bold">Kaggle Competitions</span>
      </a>
    </div>
    <div class="UnderlineNav-actions">
      <a class="UnderlineNav-item" href="../../archive/">
        <span style="font-size:1.25em;font-weight:bold">Archive</span>
      </a>
    </div>
  </nav>


  <!-- Scripts -->
  <!-- Enable MathJax -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
        SVG: { linebreaks: { automatic:true } },
    });
    MathJax.Hub.Config({
        TeX: { extensions: ["color.js"] }
    });
    MathJax.Hub.Config({
        TeX: {
            Macros: {
                formbox: ["\\bbox[15px, border:1px solid Gray]{#1}", 1],
            }
        }
    });
  </script>
  <script defer type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-133546767-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-133546767-1', { 'optimize_id': 'GTM-T3XD3JM'});
  </script>

</header>

        
        <div id="holy">

          <div id="left" class="mr-2 px-3 pb-3 text-gray bg-white">
            <div id="side">
              <div>
                <h1>Recent Posts</h1>
                <ul>
    
        <li>
          <a href="../../posts/breaking-into-tech/">How to Get a Job in Tech</a>
        </li>
    
        <li>
          <a href="../../posts/what-convnets-learn/">Visualizing What Convnets Learn</a>
        </li>
    
        <li>
          <a href="../../posts/visualizing-the-loss-landscape/">Visualizing the Loss Landscape of a Neural Network</a>
        </li>
    
        <li>
          <a href="../../posts/getting-started-with-tpus/">Getting Started with TPUs on Kaggle</a>
        </li>
    
        <li>
          <a href="../../posts/discriminant-analysis/">Six Varieties of Gaussian Discriminant Analysis</a>
        </li>
    
        <li>
          <a href="../../posts/decision/">Optimal Decision Boundaries</a>
        </li>
    
        <li>
          <a href="../../posts/least-squares-with-the-mp-inverse/">Least Squares with the Moore-Penrose Inverse</a>
        </li>
    
        <li>
          <a href="../../posts/eigenvalues-and-singular-values/">Understanding Eigenvalues and Singular Values</a>
        </li>
    
        <li>
          <a href="../../posts/visualizing-linear-transformations/">Visualizing Linear Transformations</a>
        </li>
    
        <li>
          <a href="../../posts/bayes-and-means/">What I'm Reading 1: Bayes and Means</a>
        </li>
    
</ul>

              </div>
            </div>
          </div>
            
          <div class="my-2">
          <div role="main" id="main">
  <div class="rounded-2 box-shadow-medium pb-3 px-4 bg-white">
    <!-- Post Header  -->
<div class="Subhead">
  <div class="Subhead-heading">
      <h2 class="mt-3 mb-1"><a id="post-title" href="../../posts/what-convnets-learn/">Visualizing What Convnets Learn</a></h2>
  </div>
  <div class="Subhead-description">
    
      <a href="../../tags/deep-learning/">deep-learning</a>, <a href="../../tags/convnets/">convnets</a>, <a href="../../tags/visualization/">visualization</a>, <a href="../../tags/python/">python</a>
    
    <div class="float-md-right" style="text-align=right">
      Published: January  9, 2021
      
    </div>
  </div>
</div>

<article>
  
  
  <section id="content" class="pb-2 mb-4 border-bottom">
    <p>Convolutional neural networks (or <em>convnets</em>) create task-relevant representations of the training images by learning <a href="https://en.wikipedia.org/wiki/Filter_(signal_processing)">filters</a>, which isolate from an image some feature of interest. Trained to classify images of cars, for example, a convnet might learn to filter for certain body or tire shapes.</p>
<p>In this article we’ll look at a couple ways of visualizing the filters a convnet creates during training and what kinds of features these correspond to in the training data. The first method is to look at the <em>feature maps</em> or (<em>activation maps</em>) a filter produces, which show us roughly where in an image the filter detected some feature. The second way will be through <em>optimization visuzalizations</em>, where we create an image of a filter’s preferred feature type through gradient optimization.</p>
<figure style="padding: 1em;">
<img src="../../images/optvis-mapfilter.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
Feature maps (top) and feature-optimized images (below) from ResNet50V2. Layers become deeper from left to right.
<center>
</center>
</figcaption>
</figure>
<p>Such visualizations illustrate the process of deep learning. Through deep stacks of convolutional layers, a convnet can learns to recognize a complex hierarchy of features. At each layer, features combine and recombine features from previous layers, becoming more complex and refined.</p>
<p>We’ll outline the two techniques here, but you can find the complete Python implementation <a href="https://gist.github.com/ryanholbrook/85583a7d847bb1639c3cf8a3769db68e">on Github</a>.</p>
<h1 id="the-activation-model">The Activation Model</h1>
<p>Each filter in a convolutional layer generally produces an output of shape <code>[height, width]</code>. These outputs are stacked depthwise by the layer to produce <code>[height, width, channel]</code>, one channel per filter. So a <strong>feature map</strong> is just one channel of a convolutional layer’s output. To look at feature maps, we’ll create an <strong>activation model</strong>, essentially by rerouting the output produced by a filter into a new model.</p>
<pre class="python"><code>import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import VGG16


def make_activation_model(model, layer_name, filter):
    layer = model.get_layer(layer_name)  # Grab the layer
    feature_map = layer.output[:, :, :, filter]  # Get output for the given filter
    activation_model = keras.Model(
        inputs=model.inputs,  # New inputs are original inputs (images)
        outputs=feature_map,  # New outputs are the filter's outputs (feature maps)
    )
    return activation_model


def show_feature_map(image, model, layer_name, filter, ax=None):
    act = make_activation_model(model, layer_name, filter)
    feature_map = tf.squeeze(act(tf.expand_dims(image, axis=0)))
    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(
        feature_map, cmap=&quot;magma&quot;, vmin=0.0, vmax=1.0,
    )
    return ax


# Use like:
# show_feature_map(image, vgg16, &quot;block4_conv1&quot;, filter=0)</code></pre>
<p>Here is a sample of the first few feature maps from layers in VGG16:</p>
<figure>
<img src="../../images/optvis-actmaps1.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
block1_conv2
<center>
</center>
</figcaption>
</figure>
<figure>
<img src="../../images/optvis-actmaps2.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
block2_conv2
<center>
</center>
</figcaption>
</figure>
<figure>
<img src="../../images/optvis-actmaps3.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
block3_conv2
<center>
</center>
</figcaption>
</figure>
<figure>
<img src="../../images/optvis-actmaps4.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
block4_conv1
<center>
</center>
</figcaption>
</figure>
<figure>
<img src="../../images/optvis-actmaps5.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
block5_conv3
<center>
</center>
</figcaption>
</figure>
<h1 id="optimization-visualization">Optimization Visualization</h1>
<p>What kind of feature will activate a given filter the most? We can find out by optimizing a random image through gradient ascent. We’ll use the filter’s activation model like before and train the image pixels just like we’d train the weights of a neural network.</p>
<figure>
<video autoplay loop mutued playsinline controls>
<source src="../../images/optvis-snake.webm" type="video/webm">
<source src="../../images/optvis-snake.mp4" type="video/mp4">
Can’t play the video for some reason! Click <a href="../../images/optvis-snake.gif">here</a> to download a gif. </video>
</figure>
<p>Here’s a simple Keras-style implementation:</p>
<pre class="python"><code>class OptVis:
    def __init__(
        self, model, layer, filter, size=[128, 128],
    ):
        # Activation model
        activations = model.get_layer(layer).output
        activations = activations[:, :, :, filter]
        self.activation_model = keras.Model(
            inputs=model.inputs, outputs=activations
        )
        # Random initialization image
        self.shape = [1, *size, 3]
        self.image = tf.random.uniform(shape=self.shape, dtype=tf.float32)

    def __call__(self):
        image = self.activation_model(self.image)
        return image

    def compile(self, optimizer):
        self.optimizer = optimizer

    @tf.function
    def train_step(self):
        # Compute loss
        with tf.GradientTape() as tape:
            image = self.image
            # We can include here various image parameterizations to
            # improve the optimization here. The complete code has:
            #
            # - Color decorrelation on Imagenet statistics
            # - Spatial decorrelation through a Fourier-space transform
            # - Random affine transforms: jitter, scale, rotate
            # - Gradient clipping
            #
            # These greatly improve the result
            #
            # The &quot;loss&quot; in this case is the mean activation produced
            # by the image
            loss = tf.math.reduce_mean(self.activation_model(image))
        # Apply *negative* gradient, because want *maximum* activation
        grads = tape.gradient(loss, self.image)
        self.optimizer.apply_gradients([(-grads, self.image)])
        return {&quot;loss&quot;: loss}

    @tf.function
    def fit(self, epochs=1, log=False):
        for epoch in tf.range(epochs):
            loss = self.train_step()
            if log:
                print(&quot;Score: {}&quot;.format(loss[&quot;loss&quot;]))
        image = self.image
        return to_valid_rgb(image)
</code></pre>
<p>Here is a sample from ResNet50V2:</p>
<figure>
<img src="../../images/optvis-filter-conv1_conv.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
conv1_conv
<center>
</center>
</figcaption>
</figure>
<figure>
<img src="../../images/optvis-filter-conv2_block2_out.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
conv2_block2_out
<center>
</center>
</figcaption>
</figure>
<figure>
<img src="../../images/optvis-filter-conv3_block1_out.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
conv3_block1_out
<center>
</center>
</figcaption>
</figure>
<figure>
<img src="../../images/optvis-filter-conv4_block2_out.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
conv4_block2_out
<center>
</center>
</figcaption>
</figure>
<figure>
<img src="../../images/optvis-filter-conv5_block2_out.png" width="1000" alt=" ">
<figcaption style="textalign: center; font-style: italic">
conv5_block2_out
<center>
</center>
</figcaption>
</figure>
  </section>
  
</article>

  </div>
</div>

<!-- Pagination -->
<nav class="paginate-container" aria-label="Pagination">
  <div class="pagination">
    
    <a class="previous_page text-gray-dark" rel="previous" aria-label="Previous Page" href="../../posts/visualizing-the-loss-landscape/">⮜ Previous</a>
    

    
    <a class="next_page text-gray-dark" rel="next" aria-label="Next Page" href="../../posts/breaking-into-tech/">Next ⮞</a>
    
  </div>
</nav>

<!-- Talkyard Comments -->
<div class="container-m">
  <div class="rounded-2 box-shadow-medium px-2 py-1 bg-white">
    <script>talkyardServerUrl='https://comments-for-mathformachines-com.talkyard.net';</script>
    <script async defer src="https://c1.ty-cdn.net/-/talkyard-comments.min.js"></script>
    <!-- You can specify a per page discussion id on the next line, if your URLs might change. -->
    <div class="talkyard-comments" data-discussion-id style="margin-top: 45px;">
      <noscript>Please enable Javascript to view comments.</noscript>
      <p style="margin-top: 25px; opacity: 0.9; font-size: 96%">Comments powered by
        <a href="https://www.talkyard.io">Talkyard</a>.</p>
    </div>
  </div>
</div>

          </div>
          
          <div id="right" class="ml-2 px-3 pb-3 text-gray bg-white">
            <div id="side">
              <div>
                <h1>Tags</h1>
                <a style="font-size: 100%" href="../../tags/advice/">advice</a> <a style="font-size: 105%" href="../../tags/bayesian/">bayesian</a> <a style="font-size: 100%" href="../../tags/BMA/">BMA</a> <a style="font-size: 100%" href="../../tags/calculator/">calculator</a> <a style="font-size: 100%" href="../../tags/career/">career</a> <a style="font-size: 100%" href="../../tags/category-theory/">category-theory</a> <a style="font-size: 105%" href="../../tags/classification/">classification</a> <a style="font-size: 100%" href="../../tags/convnets/">convnets</a> <a style="font-size: 100%" href="../../tags/coordinates/">coordinates</a> <a style="font-size: 100%" href="../../tags/covectors/">covectors</a> <a style="font-size: 100%" href="../../tags/cql/">cql</a> <a style="font-size: 115%" href="../../tags/data-science/">data-science</a> <a style="font-size: 105%" href="../../tags/decision-boundaries/">decision-boundaries</a> <a style="font-size: 105%" href="../../tags/deep-learning/">deep-learning</a> <a style="font-size: 100%" href="../../tags/eigenvalues/">eigenvalues</a> <a style="font-size: 100%" href="../../tags/engrams/">engrams</a> <a style="font-size: 105%" href="../../tags/finance/">finance</a> <a style="font-size: 100%" href="../../tags/functional-programming/">functional-programming</a> <a style="font-size: 100%" href="../../tags/generalized-inverse/">generalized-inverse</a> <a style="font-size: 100%" href="../../tags/geometry/">geometry</a> <a style="font-size: 100%" href="../../tags/haskell/">haskell</a> <a style="font-size: 100%" href="../../tags/investing/">investing</a> <a style="font-size: 100%" href="../../tags/julia/">julia</a> <a style="font-size: 100%" href="../../tags/kaggle/">kaggle</a> <a style="font-size: 100%" href="../../tags/LDA/">LDA</a> <a style="font-size: 100%" href="../../tags/least-squares/">least-squares</a> <a style="font-size: 115%" href="../../tags/linear-algebra/">linear-algebra</a> <a style="font-size: 100%" href="../../tags/linear-equations/">linear-equations</a> <a style="font-size: 100%" href="../../tags/matrix-decomposition/">matrix-decomposition</a> <a style="font-size: 100%" href="../../tags/MCMC/">MCMC</a> <a style="font-size: 100%" href="../../tags/memory/">memory</a> <a style="font-size: 100%" href="../../tags/moore-penrose-inverse/">moore-penrose-inverse</a> <a style="font-size: 100%" href="../../tags/neural-networks/">neural-networks</a> <a style="font-size: 100%" href="../../tags/neuroscience/">neuroscience</a> <a style="font-size: 100%" href="../../tags/NLP/">NLP</a> <a style="font-size: 100%" href="../../tags/numpy/">numpy</a> <a style="font-size: 110%" href="../../tags/python/">python</a> <a style="font-size: 100%" href="../../tags/QDA/">QDA</a> <a style="font-size: 110%" href="../../tags/R/">R</a> <a style="font-size: 100%" href="../../tags/ReLUs/">ReLUs</a> <a style="font-size: 100%" href="../../tags/retirement/">retirement</a> <a style="font-size: 100%" href="../../tags/review/">review</a> <a style="font-size: 100%" href="../../tags/sage/">sage</a> <a style="font-size: 100%" href="../../tags/sgd/">sgd</a> <a style="font-size: 100%" href="../../tags/simulation/">simulation</a> <a style="font-size: 100%" href="../../tags/singular-values/">singular-values</a> <a style="font-size: 100%" href="../../tags/stacking/">stacking</a> <a style="font-size: 100%" href="../../tags/talk/">talk</a> <a style="font-size: 100%" href="../../tags/tensorflow/">tensorflow</a> <a style="font-size: 100%" href="../../tags/tensors/">tensors</a> <a style="font-size: 100%" href="../../tags/tpus/">tpus</a> <a style="font-size: 110%" href="../../tags/tutorial/">tutorial</a> <a style="font-size: 100%" href="../../tags/vectors/">vectors</a> <a style="font-size: 105%" href="../../tags/visualization/">visualization</a>
              </div>
              <div>
                <h1>Links</h1>
                <a href="https://www.r-bloggers.com/">R-bloggers</a>
              </div>
            </div>
          </div>
        </div>

        <footer class="border p-3 bg-white text-gray">
  <div class="d-flex flex-justify-between flex-items-end">
    <div>
      Site proudly generated by <a href="http://jaspervdj.be/hakyll">Hakyll</a>.
    </div>
    <div>
<span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Math for Machines</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://mathformachines.com" property="cc:attributionName" rel="cc:attributionURL">Ryan Holbrook</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
    </div>
</footer>

        
      </div>
  </body>
</html>
